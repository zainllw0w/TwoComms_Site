#!/usr/bin/env python3
"""
Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ²ÑĞµÑ… Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†
"""
import json
from pathlib import Path
from collections import defaultdict

def analyze_pages():
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ĞºÑ€Ğ°ÑƒĞ»Ğ¸Ğ½Ğ³Ğ°
    with open('artifacts/audit_2025-10-21/crawl-results.json') as f:
        data = json.load(f)
    
    pages = data['pages']
    total = data['total_pages']
    
    print(f"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"â•‘        ĞĞĞĞ›Ğ˜Ğ— Ğ’Ğ¡Ğ•Ğ¥ Ğ¡Ğ¢Ğ ĞĞĞ˜Ğ¦ TWOCOMMS ({total} ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†)                â•‘")
    print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    
    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ ÑÑ‚Ğ°Ñ‚ÑƒÑ-ĞºĞ¾Ğ´Ğ°Ğ¼
    by_status = defaultdict(list)
    for page in pages:
        by_status[page.get('status', 'unknown')].append(page['url'])
    
    print("ğŸ“Š Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡-ĞšĞĞ”Ğ«:")
    for status, urls in sorted(by_status.items()):
        print(f"  {status}: {len(urls)} ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†")
        if status != 200 and len(urls) <= 10:
            for url in urls:
                print(f"    - {url}")
    
    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°Ğ¼
    print("\nğŸ“¦ Ğ ĞĞ—ĞœĞ•Ğ Ğ« Ğ¡Ğ¢Ğ ĞĞĞ˜Ğ¦:")
    sizes = [p.get('size', 0) for p in pages if 'size' in p]
    if sizes:
        avg_size = sum(sizes) / len(sizes)
        max_size = max(sizes)
        min_size = min(sizes)
        total_size = sum(sizes)
        
        print(f"  Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€: {avg_size/1024:.1f} KB")
        print(f"  ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹: {min_size/1024:.1f} KB")
        print(f"  ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹: {max_size/1024:.1f} KB")
        print(f"  ĞĞ±Ñ‰Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€: {total_size/1024/1024:.1f} MB")
        
        # Ğ¡Ğ°Ğ¼Ñ‹Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
        pages_with_size = [(p['url'], p['size']) for p in pages if 'size' in p]
        pages_with_size.sort(key=lambda x: x[1], reverse=True)
        
        print("\n  ğŸ“Š Ğ¢Ğ¾Ğ¿-10 ÑĞ°Ğ¼Ñ‹Ñ… Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†:")
        for i, (url, size) in enumerate(pages_with_size[:10], 1):
            print(f"    {i}. {size/1024:.1f} KB - {url}")
    
    # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ğ°Ğ¼ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†
    print("\nğŸ“‚ Ğ¢Ğ˜ĞŸĞ« Ğ¡Ğ¢Ğ ĞĞĞ˜Ğ¦:")
    page_types = defaultdict(list)
    
    for page in pages:
        url = page['url']
        if '/product/' in url:
            page_types['Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²'].append(url)
        elif '/catalog/' in url:
            page_types['ĞšĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³'].append(url)
        elif '/admin' in url or '/login' in url or '/register' in url:
            page_types['ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ'].append(url)
        elif '?page=' in url or '/?page=' in url:
            page_types['ĞŸĞ°Ğ³Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ'].append(url)
        elif '/dropshipper/' in url or '/wholesale/' in url:
            page_types['Ğ‘Ğ¸Ğ·Ğ½ĞµÑ (Ğ´Ñ€Ğ¾Ğ¿ÑˆĞ¸Ğ¿/Ğ¾Ğ¿Ñ‚)'].append(url)
        elif url.endswith('/') and url.count('/') <= 4:
            page_types['ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹'].append(url)
        else:
            page_types['ĞŸÑ€Ğ¾Ñ‡ĞµĞµ'].append(url)
    
    for ptype, urls in sorted(page_types.items(), key=lambda x: len(x[1]), reverse=True):
        print(f"  {ptype}: {len(urls)}")
        if len(urls) <= 5:
            for url in urls:
                print(f"    - {url}")
    
    # Headers Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
    print("\nğŸ” ĞĞĞĞ›Ğ˜Ğ— SECURITY HEADERS:")
    security_issues = []
    
    for page in pages:
        if page.get('status') == 200 and 'headers' in page:
            headers = page['headers']
            url = page['url']
            
            if 'Strict-Transport-Security' not in headers:
                security_issues.append(f"âŒ HSTS Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚: {url}")
            if 'X-Content-Type-Options' not in headers:
                security_issues.append(f"âŒ X-Content-Type-Options Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚: {url}")
            if 'X-Frame-Options' not in headers:
                security_issues.append(f"âŒ X-Frame-Options Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚: {url}")
    
    if security_issues:
        print(f"  ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(security_issues)} Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼")
        for issue in security_issues[:10]:
            print(f"  {issue}")
        if len(security_issues) > 10:
            print(f"  ... Ğ¸ ĞµÑ‰Ñ‘ {len(security_issues) - 10}")
    else:
        print("  âœ… Ğ’ÑĞµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ğ¸Ğ¼ĞµÑÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ security headers")
    
    # ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
    print("\nâš ï¸ ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞĞ«Ğ• Ğ¡Ğ¢Ğ ĞĞĞ˜Ğ¦Ğ«:")
    errors = [p for p in pages if p.get('status', 200) >= 400 or 'error' in p]
    if errors:
        print(f"  ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(errors)} Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†:")
        for page in errors[:20]:
            if 'error' in page:
                print(f"  âŒ {page['url']}: {page['error']}")
            else:
                print(f"  âŒ {page['url']}: HTTP {page['status']}")
    else:
        print("  âœ… ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾")
    
    # Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
    print("\nğŸ’¡ Ğ Ğ•ĞšĞĞœĞ•ĞĞ”ĞĞ¦Ğ˜Ğ˜:")
    
    product_pages = len(page_types.get('Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²', []))
    if product_pages > 50:
        print(f"  âš ï¸ {product_pages} ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² - Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ¿Ğ°Ğ³Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ/ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ")
    
    if len(pages_with_size) > 0:
        big_pages = [p for p in pages_with_size if p[1] > 500*1024]
        if big_pages:
            print(f"  âš ï¸ {len(big_pages)} ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† >500KB - Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ")
    
    if security_issues:
        print(f"  ğŸ”´ {len(security_issues)} Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ - Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ headers")
    
    print("\nâœ… ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½!")
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚
    report = {
        'total_pages': total,
        'by_status': {str(k): len(v) for k, v in by_status.items()},
        'by_type': {k: len(v) for k, v in page_types.items()},
        'avg_size_kb': avg_size/1024 if sizes else 0,
        'total_size_mb': total_size/1024/1024 if sizes else 0,
        'security_issues_count': len(security_issues),
        'errors_count': len(errors)
    }
    
    with open('artifacts/audit_2025-10-21/pages-analysis.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"\nğŸ“„ ĞÑ‚Ñ‡Ñ‘Ñ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: artifacts/audit_2025-10-21/pages-analysis.json")
    
    return report

if __name__ == '__main__':
    analyze_pages()

